{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39df77b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "flow time: 10705, util : 0.978, makespan : 545\n",
      "Tardiness: 4352, Lateness : 3069, T_max : 383\n",
      "q_true_op: 223, q_false_op : 47, q_true_job : 21, , q_false_job : 29 , q_over_time : 1493\n",
      "n_episode: 0, score : -4183.0, n_buffer : 321, eps : 8.0%\n",
      "212\n",
      "--------------------------------------------------\n",
      "flow time: 10970, util : 0.986, makespan : 546\n",
      "Tardiness: 4427, Lateness : 3334, T_max : 411\n",
      "q_true_op: 212, q_false_op : 58, q_true_job : 22, , q_false_job : 28 , q_over_time : 2046\n",
      "n_episode: 1, score : -4125.0, n_buffer : 641, eps : 8.0%\n",
      "--------------------------------------------------\n",
      "flow time: 10705, util : 0.978, makespan : 545\n",
      "Tardiness: 4352, Lateness : 3069, T_max : 383\n",
      "q_true_op: 223, q_false_op : 47, q_true_job : 21, , q_false_job : 29 , q_over_time : 1493\n",
      "n_episode: 1, score : -4183.0, n_buffer : 641, eps : 8.0%\n",
      "201\n",
      "--------------------------------------------------\n",
      "flow time: 11114, util : 0.974, makespan : 559\n",
      "Tardiness: 4499, Lateness : 3478, T_max : 375\n",
      "q_true_op: 201, q_false_op : 69, q_true_job : 16, , q_false_job : 34 , q_over_time : 2455\n",
      "n_episode: 2, score : -4561.0, n_buffer : 964, eps : 8.0%\n",
      "--------------------------------------------------\n",
      "flow time: 10705, util : 0.978, makespan : 545\n",
      "Tardiness: 4352, Lateness : 3069, T_max : 383\n",
      "q_true_op: 223, q_false_op : 47, q_true_job : 21, , q_false_job : 29 , q_over_time : 1493\n",
      "n_episode: 2, score : -4183.0, n_buffer : 964, eps : 8.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1408\\804084577.py:33: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "--------------------------------------------------\n",
      "flow time: 10760, util : 0.976, makespan : 563\n",
      "Tardiness: 4369, Lateness : 3124, T_max : 376\n",
      "q_true_op: 204, q_false_op : 66, q_true_job : 17, , q_false_job : 33 , q_over_time : 2299\n",
      "n_episode: 3, score : -4598.0, n_buffer : 1286, eps : 8.0%\n",
      "--------------------------------------------------\n",
      "flow time: 10186, util : 0.974, makespan : 568\n",
      "Tardiness: 2627, Lateness : 2550, T_max : 128\n",
      "q_true_op: 210, q_false_op : 60, q_true_job : 10, , q_false_job : 40 , q_over_time : 1719\n",
      "n_episode: 3, score : -4444.0, n_buffer : 1286, eps : 8.0%\n",
      "209\n",
      "--------------------------------------------------\n",
      "flow time: 10708, util : 0.987, makespan : 559\n",
      "Tardiness: 3126, Lateness : 3072, T_max : 137\n",
      "q_true_op: 209, q_false_op : 61, q_true_job : 11, , q_false_job : 39 , q_over_time : 2021\n",
      "n_episode: 4, score : -4441.0, n_buffer : 1606, eps : 8.0%\n",
      "--------------------------------------------------\n",
      "flow time: 10885, util : 0.977, makespan : 581\n",
      "Tardiness: 3280, Lateness : 3249, T_max : 150\n",
      "q_true_op: 209, q_false_op : 61, q_true_job : 14, , q_false_job : 36 , q_over_time : 1877\n",
      "n_episode: 4, score : -4453.0, n_buffer : 1606, eps : 8.0%\n",
      "210\n",
      "--------------------------------------------------\n",
      "flow time: 10575, util : 0.985, makespan : 575\n",
      "Tardiness: 2967, Lateness : 2939, T_max : 139\n",
      "q_true_op: 210, q_false_op : 60, q_true_job : 11, , q_false_job : 39 , q_over_time : 1816\n",
      "n_episode: 5, score : -4495.0, n_buffer : 1928, eps : 8.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 182\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Flow_time, machine_util, util, makespan, score,r_list, makespan_list, q_over_list,q_over_op\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 182\u001b[0m     Flow_time, machine_util, util, makespan, score,r_list, makespan_list, q_over_list,q_over_op \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlowTime:\u001b[39m\u001b[38;5;124m\"\u001b[39m , Flow_time)\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmachine_util:\u001b[39m\u001b[38;5;124m\"\u001b[39m , machine_util)\n",
      "Cell \u001b[1;32mIn[1], line 141\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    138\u001b[0m a, a_list \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mselect_action(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(s)\u001b[38;5;241m.\u001b[39m \u001b[38;5;28mfloat\u001b[39m(), epsilon)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m#print(a_list)\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m#print(a)\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m s_prime, r, done \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m#print(r)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m s \u001b[38;5;241m=\u001b[39m s_prime\n",
      "File \u001b[1;32m~\\main_pro\\DFJSP-Qtime\\simulator_DFJSP.py:348\u001b[0m, in \u001b[0;36mFJSP_simulator.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    346\u001b[0m machine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_availability()\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m machine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNONE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;66;03m#이벤트도 비워져 있고, #job들도 다 done이면 종료\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mj_list[job]\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDONE\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mj_list): \n",
      "File \u001b[1;32m~\\main_pro\\DFJSP-Qtime\\simulator_DFJSP.py:550\u001b[0m, in \u001b[0;36mFJSP_simulator.process_event\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    548\u001b[0m q_time_check \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39mq_time_check\n\u001b[0;32m    549\u001b[0m \u001b[38;5;66;03m#print(self.step_number) Q_Check , Q_time_over\u001b[39;00m\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplotlydf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mj] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(Type \u001b[38;5;241m=\u001b[39m event_type, JOB_ID \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39mjob\u001b[38;5;241m.\u001b[39mid  ,Task\u001b[38;5;241m=\u001b[39mevent\u001b[38;5;241m.\u001b[39mjop, Start\u001b[38;5;241m=\u001b[39mstart, Finish\u001b[38;5;241m=\u001b[39mend, Resource\u001b[38;5;241m=\u001b[39mevent\u001b[38;5;241m.\u001b[39mmachine\u001b[38;5;241m.\u001b[39mid, Rule \u001b[38;5;241m=\u001b[39m rule, \n\u001b[0;32m    551\u001b[0m                                  Step \u001b[38;5;241m=\u001b[39m step, Q_diff \u001b[38;5;241m=\u001b[39m q_time_diff, Q_check \u001b[38;5;241m=\u001b[39m q_time_check) \u001b[38;5;66;03m#간트차트를 위한 딕셔너리 생성, 데이터프레임에 집어넣음\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    817\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 818\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1785\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1782\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 1785\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1789\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:2182\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m   2181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m   2183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_maybe_update_cacher(clear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9808\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9805\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   9806\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other]\n\u001b[1;32m-> 9808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9812\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9813\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   9814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:233\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    231\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 233\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:577\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    574\u001b[0m     concat_values \u001b[38;5;241m=\u001b[39m ensure_block_shape(concat_values, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     concat_values \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_axis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat_values\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py:151\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m    148\u001b[0m             to_concat \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m to_concat]\n\u001b[0;32m    149\u001b[0m             kinds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kinds \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# GH#39817\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavior when concatenating bool-dtype and numeric-dtype arrays is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated; in a future version these will cast to object dtype \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "import collections\n",
    "import random\n",
    "from simulator_DFJSP import *\n",
    "\n",
    "learning_rate = 0.0005 \n",
    "gamma = 0.99\n",
    "buffer_limit = 50000\n",
    "batch_size = 32\n",
    "\n",
    "class ReplayBuffer():        #buffer class\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit);\n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [],[],[],[],[]\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "            \n",
    "        return torch.tensor(s_lst, dtype=torch. float),torch.tensor(a_lst), torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch. float), torch.tensor(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "class Qnet(nn.Module):        #Qnet\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12,64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.fc3 = nn.Linear(32,11)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0, 10)\n",
    "        else:\n",
    "            return out.argmax().item()\n",
    "        \n",
    "    def select_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        return out.argmax().item(),out\n",
    "        \n",
    "def train(q, q_target, memory, optimizer):\n",
    "    for i in range(10):\n",
    "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
    "        #q.number_of_time_list[a] += 1    \n",
    "        q_out = q(s)\n",
    "        q_a = q_out.gather(1,a)\n",
    "        max_q_prime = q_target(s_prime).max (1)[0].unsqueeze(1)\n",
    "        #print(max_q_prime.shape)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "def main():\n",
    "    env = FJSP_simulator('C:/Users/user/main_pro/duedate_DQN/data/FJSP_Sim_10_zero.csv','C:/Users/user/main_pro/duedate_DQN/data/FJSP_Set_10.csv',\n",
    "                          \"C:/Users/user/main_pro/duedate_DQN/data/FJSP_Q_time_10_0.4.csv\",\"C:/Users/user/main_pro/duedate_DQN/data/FJSP_rd_time_10_10,60.csv\",i)\n",
    "    q = Qnet()\n",
    "    q_target = Qnet()\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    memory = ReplayBuffer()\n",
    "    print_interval = 1\n",
    "    q_load = 10\n",
    "    score = 0.0\n",
    "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "    r_list = []\n",
    "    makespan_list = []\n",
    "    q_over_list = []\n",
    "    q_over_op = []\n",
    "    \n",
    "    for n_epi in range(2000):\n",
    "        #여기는 sample_action 구간\n",
    "        epsilon = max(0.01 , 0.08 - 0.02*(n_epi/200))\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        score = 0.0\n",
    "        while not done:\n",
    "            a = q.sample_action(torch.from_numpy(s). float(), epsilon)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            done_mask =0.0 if done else 1.0\n",
    "            if done == False:\n",
    "                memory.put((s,a,r,s_prime,done_mask))\n",
    "                s = s_prime\n",
    "                score += r\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        #학습구간    \n",
    "        if memory.size() > 1000:\n",
    "            train(q, q_target, memory, optimizer)\n",
    "        \n",
    "        #결과 및 파라미터 저장    \n",
    "        if n_epi % print_interval==0 and n_epi!=0:\n",
    "            #q_target.load_state_dict(q.state_dict())\n",
    "            params = q.state_dict()\n",
    "            Flow_time, machine_util, util, makespan, Tardiness_time, Lateness_time, T_max,q_time_true,q_time_false,q_job_t, q_job_f, q_over_time = env.performance_measure()\n",
    "            r_list.append(score/print_interval)\n",
    "            makespan_list.append(makespan)\n",
    "            q_over_list.append(q_over_time)\n",
    "            q_over_op.append(q_time_true)\n",
    "            print(q_time_true)\n",
    "            print(\"--------------------------------------------------\")\n",
    "            print(\"flow time: {}, util : {:.3f}, makespan : {}\".format(Flow_time, util, makespan))\n",
    "            print(\"Tardiness: {}, Lateness : {}, T_max : {}\".format(Tardiness_time, Lateness_time, T_max))\n",
    "            print(\"q_true_op: {}, q_false_op : {}, q_true_job : {}, , q_false_job : {} , q_over_time : {}\".format(q_time_true, q_time_false, q_job_t, q_job_f, q_over_time))\n",
    "            print(\"n_episode: {}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(n_epi, score/print_interval,memory.size(),epsilon*100))\n",
    "            #score=0.0\n",
    "        \n",
    "        #여기는 select_action 구간\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        score = 0.0\n",
    "        params = q.state_dict()\n",
    "        torch.save(params, str(n_epi) + \"nomorspt2.pt\" )\n",
    "        while not done:\n",
    "            a, a_list = q.select_action(torch.from_numpy(s). float(), epsilon)\n",
    "            #print(a_list)\n",
    "            #print(a)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            #print(r)\n",
    "            s = s_prime\n",
    "            score += r\n",
    "            if done:\n",
    "                break\n",
    "        Flow_time, machine_util, util, makespan, Tardiness_time, Lateness_time, T_max,q_time_true,q_time_false,q_job_t, q_job_f, q_over_time = env.performance_measure()\n",
    "        r_list.append(score/print_interval)\n",
    "        makespan_list.append(makespan)\n",
    "        q_over_list.append(q_over_time)\n",
    "        q_over_op.append(q_time_true)\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"flow time: {}, util : {:.3f}, makespan : {}\".format(Flow_time, util, makespan))\n",
    "        print(\"Tardiness: {}, Lateness : {}, T_max : {}\".format(Tardiness_time, Lateness_time, T_max))\n",
    "        print(\"q_true_op: {}, q_false_op : {}, q_true_job : {}, , q_false_job : {} , q_over_time : {}\".format(q_time_true, q_time_false, q_job_t, q_job_f, q_over_time))\n",
    "        print(\"n_episode: {}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(n_epi, score/print_interval,memory.size(),epsilon*100))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if n_epi % q_load ==0 and n_epi!=0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "    \n",
    "    \n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    score = 0.0\n",
    "    \n",
    "    while not done:\n",
    "        a, a_list = q.select_action(torch.from_numpy(s). float(), epsilon)\n",
    "        #print(a_list)\n",
    "        #print(a)\n",
    "        s_prime, r, done = env.step(a)\n",
    "        #print(r)\n",
    "        s = s_prime\n",
    "        score += r\n",
    "        if done:\n",
    "            break\n",
    "    Flow_time, machine_util, util, makespan, Tardiness_time, Lateness_time, T_max,q_time_true,q_time_false,q_job_t, q_job_f,q_over_time = env.performance_measure()\n",
    "    env.gannt_chart()\n",
    "    return Flow_time, machine_util, util, makespan, score,r_list, makespan_list, q_over_list,q_over_op\n",
    "for i in range(1):\n",
    "    Flow_time, machine_util, util, makespan, score,r_list, makespan_list, q_over_list,q_over_op = main()\n",
    "    print(\"FlowTime:\" , Flow_time)\n",
    "    print(\"machine_util:\" , machine_util)\n",
    "    print(\"util:\" , util)\n",
    "    print(\"makespan:\" , makespan)\n",
    "    print(\"Score\" , score)\n",
    "    \n",
    "\"\"\"    \n",
    "params = torch.load(\"nomorspt.pt\")\n",
    "q = Qnet()\n",
    "q.load_state_dict(params)\n",
    "q.eval()\n",
    "env = FJSP_simulator('C:/Users/parkh/git_tlsgudcks/simulator/data/FJSP_SIM7_all.csv','C:/Users/parkh/FJSP_SETUP_SIM.csv',\"C:/Users/parkh/git_tlsgudcks/simulator/data/FJSP_Fab.csv\",1) \n",
    "s = env.reset()\n",
    "done = False\n",
    "score = 0.0\n",
    "epsilon = max(0.01 , 0.08 - 0.02*(20/200))\n",
    "while not done:\n",
    "    a, a_list = q.select_action(torch.from_numpy(s). float(), epsilon)\n",
    "    #print(a_list)\n",
    "    #print(a)\n",
    "    s_prime, r, done = env.step(a)\n",
    "    #print(r)\n",
    "    s = s_prime\n",
    "    score += r\n",
    "    if done:\n",
    "        break\n",
    "Flow_time, machine_util, util, makespan = env.performance_measure()\n",
    "print(\"FlowTime:\" , Flow_time)\n",
    "print(\"machine_util:\" , machine_util)\n",
    "print(\"util:\" , util)\n",
    "print(\"makespan:\" , makespan)\n",
    "print(\"Score\" , score)\n",
    "\"\"\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
